{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEMANA 1\n",
    "**SET DE ENTRENAMIENTO:** Conjunto de valores (x,y) para entrenar el algoritmo. <br>\n",
    "   \n",
    "<br>**HIPÓTESIS:** Intenta predecir valores a partir de una función lineal \n",
    "$$\\theta_0+\\theta_1\\cdot x=h(x)$$\n",
    "*Donde $\\theta_k$ son los parámetros de la función.\n",
    "\n",
    "<br>**FUNCIÓN COSTO (J):** Encontrar $\\theta_0,\\theta_1[,...,\\theta_n]$ para minimizar esta función. (Error cuadrático)\n",
    "$$\\min_{\\theta_n}\\frac{1}{2m}\\sum_{i=1}^m{\\left(h(x^{(i)})-y^{(i)}\\right)^2}=\\min_{\\theta_n}J(\\theta)$$\n",
    "*Donde $(x^{(i)},y^{(i)})$ es la i-ésima pareja del set de entrenamiento.\n",
    "\n",
    "<br>**ALGORITMO - DESCENSO POR GRADIENTE:** <br>\n",
    "*(para dos parámetros)*<br>\n",
    ">1. Iniciar con *algún* $\\theta_0,\\theta_1$ <br>\n",
    ">2. Ir cambiando $\\theta_0,\\theta_1$ simultaneamente para reducir $J(\\theta_0,\\theta_1)$ hasta encontrar su mínimo<br>\n",
    "\n",
    "$$\n",
    "\\textrm{repetir hasta que }\\Delta_{\\theta_j}\\lt\\textrm{M} \\\\\n",
    "\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial{\\theta_j}}J(\\theta_0,\\theta_1) \\\\\n",
    "\\textrm{Para  } j=0,1\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $M$ es un umbral definido\n",
    "- $\\alpha$ es la *tasa de aprendizaje* del algoritmo (qué tan rápido cambian los valores de $\\theta_j$)\n",
    "\n",
    "\n",
    "<br>**DESCENSO POR GRADIENTE PARA REGRESIÓN LINEAL:**<br>\n",
    "*(para dos parámetros)*<br>\n",
    "Debido a naturaleza convexa de la función costo, descenso por gradiente siempre encuentra el mínimo global de la función. Entonces este algoritmo puede ser utilizado para minimizarla. <br><br>\n",
    "Sabiendo que: \n",
    "$$\n",
    "h(x)=\\theta_0+\\theta_1\\cdot x \\\\\n",
    "J(\\Theta)=\\frac{1}{2m}\\sum_{i=1}^m{\\left(h(x^{(i)})-y^{(i)}\\right)^2}\\\\\n",
    "\\theta_0:=\\theta_0-\\alpha\\frac{\\partial}{\\partial{\\theta_0}}J(\\theta_0,\\theta_1)\\\\\n",
    "\\theta_1:=\\theta_1-\\alpha\\frac{\\partial}{\\partial{\\theta_1}}J(\\theta_0,\\theta_1)\\\\\n",
    "$$\n",
    "Hallando derivadas:\n",
    "$$\n",
    "\\frac{\\partial}{\\partial{\\theta_j}}J(\\theta_0,\\theta_1)= \\frac{\\partial}{\\partial{\\theta_j}}\\frac{1}{2m}\\sum_{i=1}^m{\\left(\\theta_0+\\theta_1\\cdot x^{(i)}-y^{(i)}\\right)^2} \\\\\n",
    "\\frac{\\partial}{\\partial{\\theta_0}}J(\\theta_0,\\theta_1)= \\frac{1}{m}\\sum_{i=1}^m{\\left(\\theta_0+\\theta_1\\cdot x^{(i)}-y^{(i)}\\right)} \\\\\n",
    "\\frac{\\partial}{\\partial{\\theta_1}}J(\\theta_0,\\theta_1)= \\frac{1}{m}\\sum_{i=1}^m{\\left(\\theta_0+\\theta_1\\cdot x^{(i)}-y^{(i)}\\right)}\\cdot x^{(i)}\n",
    "$$\n",
    "Entonces:\n",
    "$$\n",
    "\\theta_0:=\\theta_0-\\alpha\\frac{1}{m}\\sum_{i=1}^m{\\left(h(x^{(i)})-y^{(i)}\\right)}\\\\\n",
    "\\theta_1:=\\theta_1-\\alpha\\frac{1}{m}\\sum_{i=1}^m{\\left(h(x^{(i)})-y^{(i)}\\right)}\\cdot x^{(i)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver código en regresionLineal.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEMANA 2\n",
    "**MÚLTIPLES CARACTERÍSTICAS:** Ahora se tienen en cuenta $n$ parámetros para cada fila.<br>\n",
    " - $x^{(i)}$ es el vector de parámetros de entrada para la i-ésima fila. <br>\n",
    " - $x_j^{(i)}$ es el valor del j-ésimo parámetro de la i-ésima fila.\n",
    "\n",
    " Ahora hipótesis es:\n",
    " $$\n",
    " h_\\theta(x)=\\theta_0\\cdot x_0+\\theta_1\\cdot x_1+\\theta_2\\cdot x_2+...+\\theta_n\\cdot x_n\n",
    " $$\n",
    " Donde $x_0=1$ <br>\n",
    " $x$ y $\\theta$ se pueden representar como:\n",
    " $$\n",
    " x=\n",
    " \\begin{bmatrix} \n",
    "    x_0  \\\\ \n",
    "    x_1  \\\\ \n",
    "    ...  \\\\\n",
    "    x_n\n",
    " \\end{bmatrix}\n",
    " $$\n",
    "y\n",
    " $$\n",
    " \\theta=\n",
    " \\begin{bmatrix} \n",
    "    \\theta_0  \\\\ \n",
    "    \\theta_1  \\\\ \n",
    "    ...  \\\\\n",
    "    \\theta_n\n",
    " \\end{bmatrix}\n",
    " \n",
    " $$\n",
    "\n",
    " Entonces:\n",
    " $$\n",
    " h(x)=\\theta^T \\cdot x\n",
    " $$\n",
    "\n",
    " **DESCENSO POR GRADIENTE PARA MÚLTIPLES CARACTERÍSTICAS:**<br>\n",
    " Función costo:\n",
    " $$\n",
    " J(\\Theta)=\\frac{1}{2m}\\cdot \\sum_{i=1}^m\\left(h_\\theta(x^{(i)})-y^{(i)}\\right)^2\n",
    " $$\n",
    " Algoritmo:\n",
    " $$\n",
    "\\textrm{repetir hasta que }\\Delta_{\\theta_j}\\lt\\textrm{M} \\\\\n",
    "\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial{\\theta_j}}J(\\Theta) \\\\\n",
    "\\rightarrow\\theta_j:=\\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^m\\left( (h_\\theta(x^{i})-y^{(i)})\\cdot x_j^{(i)}\\right) \\\\\n",
    "\\textrm{Para todo } j=0..n\n",
    "$$\n",
    "$$\n",
    "\n",
    "**ESCALAMIENTO DE CARACTERÍSTICAS:**<br>\n",
    "Si una característica de entrada tiene valores muy diferentes a otras características de entrada o salida, es conveniente normalizar estas características a valores cercanos a $-1 < x < 1$, de la forma:\n",
    "$$\n",
    "x=\\frac{x-\\mu_x}{\\sigma_x}\n",
    "$$\n",
    "Donde, $\\mu_x$ es la media de $x$ y $\\sigma_x$ es la desviación estándar o el rango de valores de $x$ (Es decir, $x_{max}-x_{min}$)\n",
    "\n",
    "**CARACTERÍSTICAS Y REGRESIÓN POLINOMIAL:**<br>\n",
    " - Es posible unir varias características para simplificar un modelo. Por ejemplo si dos de mis características son *Largo* y *Ancho*, puede ser que la nueva característica sea $Area=Largo\\cdot Ancho$\n",
    " - Es posible convertir la regresión lineal en regresión polinomial, si simplemente escalamos las características a diferentes potencias. Por ejemplo (siendo x una característica de entrada): \n",
    " $$\n",
    " y=\\theta_0+x\\cdot \\theta_1+x^2\\cdot \\theta_2\n",
    " $$\n",
    "\n",
    " Se puede modelar de manera sencilla simplemente creando un arreglo con x^2. Este procedimiento puede ser replicado para otras funciones matemáticas, por ejemplo $\\sqrt{x}$ o $\\ln{x}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEMANA 3\n",
    "\n",
    "***CLASIFICACIÓN BINARIA:*** Utiliza función logística o sigmoide. De la forma:\n",
    "$$$\n",
    "h_\\theta(x)=g(\\theta^Tx) \\\\\n",
    "z=\\theta^Tx \\\\\n",
    "g(z)=\\frac{1}{1+e^{-z}}\n",
    "$$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.794375pt\" version=\"1.1\" viewBox=\"0 0 385.78125 277.794375\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.794375 \n",
       "L 385.78125 277.794375 \n",
       "L 385.78125 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 240.238125 \n",
       "L 378.58125 240.238125 \n",
       "L 378.58125 22.798125 \n",
       "L 43.78125 22.798125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 58.999432 240.238125 \n",
       "L 58.999432 22.798125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m9add763b79\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#m9add763b79\" y=\"240.238125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −8 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.59375 35.5 \n",
       "L 73.1875 35.5 \n",
       "L 73.1875 27.203125 \n",
       "L 10.59375 27.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-8722\"/>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(51.628338 254.836563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-8722\"/>\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 97.044886 240.238125 \n",
       "L 97.044886 22.798125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.044886\" xlink:href=\"#m9add763b79\" y=\"240.238125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −6 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(89.673793 254.836563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-8722\"/>\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 135.090341 240.238125 \n",
       "L 135.090341 22.798125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"135.090341\" xlink:href=\"#m9add763b79\" y=\"240.238125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- −4 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(127.719247 254.836563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-8722\"/>\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 173.135795 240.238125 \n",
       "L 173.135795 22.798125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"173.135795\" xlink:href=\"#m9add763b79\" y=\"240.238125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- −2 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(165.764702 254.836563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-8722\"/>\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 211.18125 240.238125 \n",
       "L 211.18125 22.798125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"211.18125\" xlink:href=\"#m9add763b79\" y=\"240.238125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(208 254.836563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 249.226705 240.238125 \n",
       "L 249.226705 22.798125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"249.226705\" xlink:href=\"#m9add763b79\" y=\"240.238125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(246.045455 254.836563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 287.272159 240.238125 \n",
       "L 287.272159 22.798125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"287.272159\" xlink:href=\"#m9add763b79\" y=\"240.238125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(284.090909 254.836563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 325.317614 240.238125 \n",
       "L 325.317614 22.798125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"325.317614\" xlink:href=\"#m9add763b79\" y=\"240.238125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(322.136364 254.836563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 363.363068 240.238125 \n",
       "L 363.363068 22.798125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.363068\" xlink:href=\"#m9add763b79\" y=\"240.238125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(360.181818 254.836563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- z -->\n",
       "     <defs>\n",
       "      <path d=\"M 5.515625 54.6875 \n",
       "L 48.1875 54.6875 \n",
       "L 48.1875 46.484375 \n",
       "L 14.40625 7.171875 \n",
       "L 48.1875 7.171875 \n",
       "L 48.1875 0 \n",
       "L 4.296875 0 \n",
       "L 4.296875 8.203125 \n",
       "L 38.09375 47.515625 \n",
       "L 5.515625 47.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-122\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(208.557031 268.514687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-122\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 43.78125 230.420823 \n",
       "L 378.58125 230.420823 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m0159121033\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0159121033\" y=\"230.420823\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 234.220041)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 43.78125 190.859744 \n",
       "L 378.58125 190.859744 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0159121033\" y=\"190.859744\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(20.878125 194.658962)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 43.78125 151.298665 \n",
       "L 378.58125 151.298665 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0159121033\" y=\"151.298665\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(20.878125 155.097883)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 43.78125 111.737585 \n",
       "L 378.58125 111.737585 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0159121033\" y=\"111.737585\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(20.878125 115.536804)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 43.78125 72.176506 \n",
       "L 378.58125 72.176506 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0159121033\" y=\"72.176506\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(20.878125 75.975725)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path clip-path=\"url(#p8c744b2873)\" d=\"M 43.78125 32.615427 \n",
       "L 378.58125 32.615427 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_30\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0159121033\" y=\"32.615427\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 1.0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 36.414646)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- y -->\n",
       "     <defs>\n",
       "      <path d=\"M 32.171875 -5.078125 \n",
       "Q 28.375 -14.84375 24.75 -17.8125 \n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \n",
       "L 7.90625 -20.796875 \n",
       "L 7.90625 -13.28125 \n",
       "L 13.1875 -13.28125 \n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \n",
       "Q 21 -9.765625 23.484375 -3.21875 \n",
       "L 25.09375 0.875 \n",
       "L 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 11.921875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-121\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 134.4775)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-121\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_31\">\n",
       "    <path clip-path=\"url(#p8c744b2873)\" d=\"M 58.999432 230.354489 \n",
       "L 62.073812 230.342858 \n",
       "L 65.148192 230.329188 \n",
       "L 68.222572 230.313123 \n",
       "L 71.296952 230.294244 \n",
       "L 74.371333 230.272058 \n",
       "L 77.445713 230.245986 \n",
       "L 80.520093 230.21535 \n",
       "L 83.594473 230.179352 \n",
       "L 86.668853 230.137057 \n",
       "L 89.743233 230.087366 \n",
       "L 92.817614 230.02899 \n",
       "L 95.891994 229.960419 \n",
       "L 98.966374 229.879881 \n",
       "L 102.040754 229.7853 \n",
       "L 105.115134 229.674245 \n",
       "L 108.189514 229.543869 \n",
       "L 111.263895 229.390844 \n",
       "L 114.338275 229.211282 \n",
       "L 117.412655 229.00064 \n",
       "L 120.487035 228.753627 \n",
       "L 123.561415 228.464079 \n",
       "L 126.635795 228.124833 \n",
       "L 129.710176 227.727579 \n",
       "L 132.784556 227.262703 \n",
       "L 135.858936 226.719107 \n",
       "L 138.933316 226.084028 \n",
       "L 142.007696 225.342844 \n",
       "L 145.082076 224.478878 \n",
       "L 148.156457 223.473216 \n",
       "L 151.230837 222.304547 \n",
       "L 154.305217 220.949051 \n",
       "L 157.379597 219.38035 \n",
       "L 160.453977 217.569571 \n",
       "L 163.528357 215.48555 \n",
       "L 166.602738 213.095234 \n",
       "L 169.677118 210.364316 \n",
       "L 172.751498 207.258186 \n",
       "L 175.825878 203.743211 \n",
       "L 178.900258 199.788391 \n",
       "L 181.974638 195.367383 \n",
       "L 185.049019 190.460832 \n",
       "L 188.123399 185.058914 \n",
       "L 191.197779 179.163881 \n",
       "L 194.272159 172.792362 \n",
       "L 197.346539 165.977112 \n",
       "L 200.420919 158.767865 \n",
       "L 203.4953 151.23102 \n",
       "L 206.56968 143.447962 \n",
       "L 209.64406 135.512021 \n",
       "L 212.71844 127.524229 \n",
       "L 215.79282 119.588288 \n",
       "L 218.8672 111.80523 \n",
       "L 221.941581 104.268385 \n",
       "L 225.015961 97.059138 \n",
       "L 228.090341 90.243888 \n",
       "L 231.164721 83.872369 \n",
       "L 234.239101 77.977336 \n",
       "L 237.313481 72.575418 \n",
       "L 240.387862 67.668867 \n",
       "L 243.462242 63.247859 \n",
       "L 246.536622 59.293039 \n",
       "L 249.611002 55.778064 \n",
       "L 252.685382 52.671934 \n",
       "L 255.759762 49.941016 \n",
       "L 258.834143 47.5507 \n",
       "L 261.908523 45.466679 \n",
       "L 264.982903 43.6559 \n",
       "L 268.057283 42.087199 \n",
       "L 271.131663 40.731703 \n",
       "L 274.206043 39.563034 \n",
       "L 277.280424 38.557372 \n",
       "L 280.354804 37.693406 \n",
       "L 283.429184 36.952222 \n",
       "L 286.503564 36.317143 \n",
       "L 289.577944 35.773547 \n",
       "L 292.652324 35.308671 \n",
       "L 295.726705 34.911417 \n",
       "L 298.801085 34.572171 \n",
       "L 301.875465 34.282623 \n",
       "L 304.949845 34.03561 \n",
       "L 308.024225 33.824968 \n",
       "L 311.098605 33.645406 \n",
       "L 314.172986 33.492381 \n",
       "L 317.247366 33.362005 \n",
       "L 320.321746 33.25095 \n",
       "L 323.396126 33.156369 \n",
       "L 326.470506 33.075831 \n",
       "L 329.544886 33.00726 \n",
       "L 332.619267 32.948884 \n",
       "L 335.693647 32.899193 \n",
       "L 338.768027 32.856898 \n",
       "L 341.842407 32.8209 \n",
       "L 344.916787 32.790264 \n",
       "L 347.991167 32.764192 \n",
       "L 351.065548 32.742006 \n",
       "L 354.139928 32.723127 \n",
       "L 357.214308 32.707062 \n",
       "L 360.288688 32.693392 \n",
       "L 363.363068 32.681761 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 240.238125 \n",
       "L 43.78125 22.798125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 378.58125 240.238125 \n",
       "L 378.58125 22.798125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 240.238125 \n",
       "L 378.58125 240.238125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 22.798125 \n",
       "L 378.58125 22.798125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_18\">\n",
       "    <!-- Función logística -->\n",
       "    <defs>\n",
       "     <path d=\"M 9.8125 72.90625 \n",
       "L 51.703125 72.90625 \n",
       "L 51.703125 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.109375 \n",
       "L 48.578125 43.109375 \n",
       "L 48.578125 34.8125 \n",
       "L 19.671875 34.8125 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-70\"/>\n",
       "     <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "     <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "     <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "     <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "     <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "M 37.40625 79.984375 \n",
       "L 47.125 79.984375 \n",
       "L 31.21875 61.625 \n",
       "L 23.734375 61.625 \n",
       "z\n",
       "\" id=\"DejaVuSans-243\"/>\n",
       "     <path id=\"DejaVuSans-32\"/>\n",
       "     <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "     <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "     <path d=\"M 45.40625 27.984375 \n",
       "Q 45.40625 37.75 41.375 43.109375 \n",
       "Q 37.359375 48.484375 30.078125 48.484375 \n",
       "Q 22.859375 48.484375 18.828125 43.109375 \n",
       "Q 14.796875 37.75 14.796875 27.984375 \n",
       "Q 14.796875 18.265625 18.828125 12.890625 \n",
       "Q 22.859375 7.515625 30.078125 7.515625 \n",
       "Q 37.359375 7.515625 41.375 12.890625 \n",
       "Q 45.40625 18.265625 45.40625 27.984375 \n",
       "z\n",
       "M 54.390625 6.78125 \n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \n",
       "Q 42 -20.796875 29.203125 -20.796875 \n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \n",
       "L 12.109375 -9.1875 \n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \n",
       "Q 23.78125 -13.375 27.78125 -13.375 \n",
       "Q 36.625 -13.375 41.015625 -8.765625 \n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \n",
       "L 45.40625 9.625 \n",
       "Q 42.625 4.78125 38.28125 2.390625 \n",
       "Q 33.9375 0 27.875 0 \n",
       "Q 17.828125 0 11.671875 7.65625 \n",
       "Q 5.515625 15.328125 5.515625 27.984375 \n",
       "Q 5.515625 40.671875 11.671875 48.328125 \n",
       "Q 17.828125 56 27.875 56 \n",
       "Q 33.9375 56 38.28125 53.609375 \n",
       "Q 42.625 51.21875 45.40625 46.390625 \n",
       "L 45.40625 54.6875 \n",
       "L 54.390625 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-103\"/>\n",
       "     <path d=\"M 20.65625 79.984375 \n",
       "L 30.375 79.984375 \n",
       "L 14.46875 61.625 \n",
       "L 6.984375 61.625 \n",
       "z\n",
       "M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 13.921875 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-237\"/>\n",
       "     <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "     <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "     <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(160.84875 16.798125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "     <use x=\"57.441406\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"120.820312\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"184.199219\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"239.179688\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"266.962891\" xlink:href=\"#DejaVuSans-243\"/>\n",
       "     <use x=\"328.144531\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"391.523438\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"423.310547\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"451.09375\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"512.275391\" xlink:href=\"#DejaVuSans-103\"/>\n",
       "     <use x=\"575.751953\" xlink:href=\"#DejaVuSans-237\"/>\n",
       "     <use x=\"603.535156\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"655.634766\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"694.84375\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"722.626953\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"777.607422\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p8c744b2873\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"22.798125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z=np.linspace(-8,8,num=100)\n",
    "y=1/(1+np.exp(-1*z))\n",
    "plt.plot(z,y)\n",
    "plt.title(\"Función logística\"); plt.xlabel(\"z\"); plt.ylabel(\"y\"); plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función logística $h_\\theta(x)$ mapea cualquier número real al intervalo (0,1). <br>\n",
    "$h_\\theta(x)$ indica la probabilidad de que la salida del algoritmo sea $1$, es decir:\n",
    "$$$ \n",
    "h_\\theta(x)=P(y=1|x; \\theta) \\\\\n",
    "P(y=1|x; \\theta)+P(y=0|x; \\theta)=1\n",
    "$$$\n",
    "\n",
    "***UMBRAL DE DECISIÓN:*** <br>\n",
    "El algoritmo podría escoger la categoría \"1\" si la salida de $h_\\theta(x)>0.5$ <br>\n",
    "Esto ocurre cuando $z>0\\quad =\\quad\\theta^Tx>0$.\n",
    "<br><br>\n",
    "\n",
    "***REGRESIÓN LOGÍSTICA:***<br>\n",
    "- Aprendizaje supervisado.\n",
    "- Definición del problema:\n",
    "  - Set de entrenamiento con $m$ ejemplos: \n",
    "  \n",
    "  $$\n",
    "  \\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\\} \\\\\n",
    "  x \\in  \n",
    "  \\begin{bmatrix} \n",
    "    x_0  \\\\ \n",
    "    x_1  \\\\ \n",
    "    ...  \\\\\n",
    "    x_n\n",
    " \\end{bmatrix}\n",
    "\n",
    " $$\n",
    "Donde, $x_0=1 \\quad , \\quad y \\in \\{0,1\\}$\n",
    "y\n",
    "$$\n",
    "h_\\theta(x)=\\frac{1}{1+e^{-\\theta^Tx}}\n",
    "$$\n",
    "\n",
    "- Para hallar parámetros ($\\theta$):\n",
    "   - Función costo (maximum likelihood estimtation):\n",
    "   $$\n",
    "   \\textrm{Costo}\\left(h_\\theta(x),y\\right)=\n",
    "   \\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t-\\log{(h_\\theta(x))}   & \\mbox{if   } y = 1  \\\\\n",
    "\t\t-\\log{(1-h_\\theta(x))} & \\mbox{if   } y = 0\n",
    "\t\\end{array}\n",
    "   \\right.\n",
    "   $$\n",
    "   Simplificando:\n",
    "   $$\n",
    "   \\textrm{Costo}\\left(h_\\theta(x),y\\right)=\n",
    "   -y\\cdot \\log{(h_\\theta(x))}-(1-y)\\cdot \\log{(1-h_\\theta(x))} \n",
    "   $$\n",
    "   Entonces:\n",
    "   $$\n",
    "   J(\\Theta)=\\frac{1}{m}\\sum_{i=1}^m\\textrm{Costo}\\left(h_\\theta(x^{(i)}),y^{(i)}\\right) \\\\   \n",
    "   J(\\Theta)=\\frac{1}{m}\\sum_{i=1}^m -y^{(i)}\\cdot \\log{(h_\\theta(x^{(i)}))}-(1-y^{(i)})\\cdot \\log{(1-h_\\theta(x^{(i)}))} \n",
    "   $$\n",
    "   Para ajustar parámetros, minimizar $J(\\Theta)$\n",
    "\n",
    "   - Descenso por gradiente para $n$ parámetros $\\theta$:\n",
    "   $$\n",
    "   \\textrm{repetir hasta que }\\Delta_{\\theta_j}\\lt\\textrm{M} \\\\\n",
    "   \\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial{\\theta_j}}J(\\Theta) \\\\\n",
    "   \\rightarrow\\theta_j:=\\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^m\\left( (h_\\theta(x^{i})-y^{(i)})\\cdot x_j^{(i)}\\right) \\\\\n",
    "   \\textrm{Para todo } j=0..n\n",
    "   $$\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN\n",
    "\n",
    "- Cada capa tiene su propia matriz $\\Theta^{(n)}$ en donde cada fila son los parámetros (o pesos) de su función de activación de uno de sus nodos. Las filas representan diferentes nodos dentro de la capa.\n",
    "\n",
    "- El vector de entrada de cada capa ($a^{(n)}$)  equivale al vector de salida de la capa anterior.\n",
    "\n",
    "- La red debe aprender sus propios parámetros para cada una de sus capas. Cada capa subsecuente crea parámetros más complejos, que son utilizados por la siguiente capa como entrada.\n",
    "\n",
    "- Para cada capa: $z^{(n)}=\\Theta^{(n-1)}\\cdot a^{(n-1)}$ y $a^{(n)}=g(z^{(n)})$ donde $g$ es la función de activación de la capa. (Por ejemplo el sigmoide de la regresión logística)\n",
    "    - $\\Theta^{(1)}$ son los parámetros de transición de la capa 1 a la capa dos ($\\Theta^{(1->2)}$)\n",
    "\n",
    "- Ejemplo: A XNOR B = (A AND B) OR ((NOT A) AND (NOT B))\n",
    "    - A AND B puede ser representado como una NN sencilla, igual que la segunda parte de la función. A OR B puede ser una NN sencilla, al unir ambas partes se forma una NN con una capa oculta\n",
    "    - Esto también puede ser resuelto añadiendo una dimensión al problema, y utilizando un plano (no una linea) para separar ambas clases *(ver svm)*\n",
    "\n",
    "- Clasificación multiclase aún se hace Uno vs. Todos\n",
    "\n",
    "# NN sencilla\n",
    "\n",
    "- La salida de cada neurona es $a^{(n)}=g(z^{(n-1)})=g\\left(\\theta^{(n-1)} \\cdot a^{(n-1)}\\right)$    \n",
    "\n",
    "    - Donde $\\theta^{(n-1)}$ son los parámetros ($\\theta_0,\\theta_1,...,\\theta_n$) de ese nodo en específico\n",
    "    - $a^{(n-1)}$ son los valores de entrada al nodo\n",
    "    - $g(x)$ es la función de activación de la capa\n",
    "    - $\\Theta$ contiene todos los parámetros de una capa (uniendo los vectores $\\theta$ de cada nodo de la capa)\n",
    " - La función costo (J) se puede representar como: $J(\\Theta)=\\frac{1}{m}\\sum_1^mCosto(x_{pred},y)$\n",
    "    - Donde $Costo(x,y)$ puede ser el Error Cuadrático Medio (MSE) o cualquier función de costo.\n",
    "    - Es decir: El error de la salida, con respecto a la predicción de la red, promediado para todos los ejemplos.    \n",
    "    \n",
    "- Gradient descent es modificar los parámetros de un nodo (o capa, si se utiliza la matriz $\\Theta$) según la dirección en la que el promedio del error (para todos los elementos del conjunto de pruebas) disminuye más $\\left(\\Theta =\\Theta -\\nabla J(\\Theta)\\right)$\n",
    "\n",
    "# Backpropagation \n",
    "Ver https://developers-dot-devsite-v2-prod.appspot.com/machine-learning/crash-course/backprop-scroll\n",
    "\n",
    "**(REVISAR E IMPLEMENTAR ESTAS ECUACIONES)**\n",
    " - Algoritmo para hallar los parámetros $\\Theta$ para todas las capas red neuronal.  \n",
    " - Sabiendo que para una capa n: $\\Theta^{(n)}=\\Theta^{(n)}-\\alpha \\frac{\\partial J}{\\partial \\Theta^{(n)}}$.\n",
    "    -(durante el entrenamiento para *gradient descent* en la iteración $\\tau$)\n",
    " - Se quiere hallar $\\frac{\\partial J}{\\partial \\Theta^{(n)}_{ij}}$ para cualquier capa $n$ \n",
    " - Entonces:     \n",
    "    - A partir de $a^{(L)}$ (Valor de salida), calcular $\\delta^{(L)}=a^{(L)}-y$     \n",
    "    - Calcular $\\delta^{(n)}= (\\Theta^{(n)}\\cdot \\delta^{(n+1)})\\ \\cdot g'(z^{(n)})$, desde la capa $n=L-1$ hacia atras.         \n",
    "        - Donde $a^{(n)}$ es la salida de la capa y $\\delta^{(n)}$ es el *error* de la capa.\n",
    " \n",
    "        - Esta ecuación se puede derivar a partir de la regla de la cadena para $\\frac{\\partial J}{\\partial \\Theta^{(n)}_{ij}}$\n",
    "    - Luego, $\\frac{\\partial J}{\\partial \\Theta^{(n)}_{ij}}=\\delta^{(n)} \\cdot a^{(n-1)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(APUNTES DE HARVARD CS109)\n",
    "# KNN (k-Nearest Neighbors)\n",
    "- Clasificación o regresión\n",
    "- Según la entrada, busca los $k$ elementos \"cercanos\" y decide a qué clase pertenece según mayoría de estos. (Si k=1 -> Voronoi)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"imgs/knn2.png\">\n",
    "</p>\n",
    "\n",
    "- Ejemplo para diferentes $k$:\n",
    "  - Si $k=3$ (círculo pequeño), se clasifica como triángulo rojo.\n",
    "  - Si $k=5$ (círculo grande), se clasifica como cuadrado azul.\n",
    "  \n",
    "<p align=\"center\">\n",
    "  <img src=\"imgs/knn1.png\">\n",
    "</p>\n",
    "\n",
    "- Algoritmo:\n",
    "  - Almacenar todos los parámetros.\n",
    "  - Determinar el modelo de \"cercanía\" (eg. suma de distancias euclidianas)\n",
    "  - Hallar los $k$ elementos más cercano.\n",
    "  - Hacer voto por mayoría (clasificación) o promedio (regresión) para definir el resultado del modelo\n",
    "\n",
    "- Baja complejidad O(n) en entrenamiento, alta complejidad O(m*n) en clasificación.\n",
    "- (Hiper)parámetros del modelo:\n",
    "  - $k$ óptimo\n",
    "  - Función de cercanía o distancia\n",
    "  - Función de \"mayoría\"\n",
    "  <br> <br>\n",
    "- Para obtener $k$ (o cualquier otro hiperparámetro) óptimo (cross-validation):\n",
    "  - Separar el set de entrenamiento en $n$ particiones.\n",
    "  - Para un valor de $k$, entrenar $n-1$ de las particiones y validar con la restante (set de validación).\n",
    "    - Rotar el set de validación y hallar su eficacia para cada uno\n",
    "  - Repetir para todos los valores de $k$ que se deseen probar y hallar el promedio de eficiacia para cada uno.\n",
    "  - Escoger el parámetro con mejores resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(APUNTES DE HARVARD CS109, STANFORD CS229 y Coursera)\n",
    "# SVMs (Support Vector Machines)\n",
    "\n",
    "- \"Separación de hiperplanos\"\n",
    "    - Encontrar la frontera o umbral de decisión (decision boundary)\n",
    "    - La frontera es n-dimensional (puede ser una recta, plano, volumen... por eso hiperplano)\n",
    "    - Representada como $w^Tx+b=0$ (igual que en regresión y NN), en donde la dirección de $\\vec{w}$ indica la clase \"positivos\" de la clasificación.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"imgs/svm1.png\">\n",
    "</p>\n",
    "\n",
    "- Los únicos parámetros utilizados en la ecuación es el vector de pesos $\\vec{w}$\n",
    "  - $y_{pred}= g(b+w_1x_1+w_2x_2+...+w_nx_n)=g(w^Tx+b)=g(\\theta^Tx)=g(w\\cdot x+b)$\n",
    "  - $g(z)$ es la *función de activación*, que puede ser: paso, sigmoide...\n",
    "    - Para un SVM lineal, g(z)=función paso -> z>0=1; z<0=-1\n",
    "- Predicción más rápida: únicamente evalúa ecuación. \n",
    "\n",
    "- SVM siempre escoge el hiperplano con máxima separación de clases.\n",
    "  - Los \"vectores de soporte\" son los elementos de entrenamiento que dan esta máxima separación del hiperplano a cada clase (puntos más cercanos al umbral de decisión)\n",
    "  - Estos vectores de soporte definen el modelo.\n",
    "  <p align=\"center\">\n",
    "    <img src=\"imgs/svm2.png\">\n",
    "  </p>\n",
    "  - $\\gamma^{(i)}$ es la distancia del vector de soporte $x^{(i)}$ al umbral\n",
    "  - Se desea **maximizar ** $\\gamma$ (Problema de optimización)\n",
    "\n",
    "- Para realizar predicción:\n",
    "  - Resultado obtenido a partir de resolver problema de optimización cuadrático (Ver documentos)\n",
    "  - Se encuentra que:\n",
    "  $$\n",
    "  w^Tx+b=\\sum_{i=1}^m\\alpha_iy^{(i)}\\langle x^{(i)},x\\rangle +b\n",
    "  $$\n",
    "  - Donde:\n",
    "    - x es un punto de entrada nuevo\n",
    "    - x^{(i)} es todo el conjunto de entrenamiento\n",
    "    - $\\alpha=0$ para todos los $x^{(i)}$ que no son vectores de soporte.\n",
    "  - La forma $\\langle x^{(i)},x\\rangle$ permite el uso de Kernels para realizar predicciones complejas.\n",
    "\n",
    "\n",
    "\n",
    "- SVM generalmente eleva dimensiones del problema para permitir clasificación más compleja mediante Kernels.\n",
    "\n",
    "## Núcleos (kernel)\n",
    "- Permiten simplificar los cálculos computacionales para obtener umbrales de decisión complejos (con características polinomiales, por ejemplo)\n",
    "- Representan una transformación del espacio de entrada al espacio de características:\n",
    "  - $K(x,z)=\\langle \\Phi{(x)},\\Phi{(z)}\\rangle$\n",
    "    - Donde $\\Phi{(x)}$ representa la correlación (mapeo) de $x$ al espacio de características \n",
    "- Tipos:\n",
    "  - Núcleo (kernel) polinomial \\[grado $s$, bias $b$]: $ K(x,z)=(b+x\\cdot z)^s $\n",
    "    - Usado en clasificación de imágenes\n",
    "  - Núcleo RBF (Radial basis function) \\[parámetro $\\gamma$]: $e^{-\\gamma (x-z)^2}$\n",
    "    - Se puede demostrar que RBF puede llegar a un número \"infinito\" de dimensiones\n",
    "    - Bueno para hacer pruebas (buen desempeño en mayoría de casos)\n",
    "  - Kernel Gaussiano \\[parámetro $\\sigma$]: $\\exp{\\left(-\\frac{\\Vert x-z \\Vert^2}{2\\sigma^2}\\right)}$\n",
    "    - Se usa para problemas con pocas características y/o muchos ejemplos\n",
    "    - Similar a RBF\n",
    "  - Otros tipos de Kernel para diferentes aplicaciones.\n",
    "\n",
    "  <p align=\"center\">  \n",
    "    <img src=\"imgs/svm3.png\">\n",
    "  </p>\n",
    "  \n",
    "- El parámetro $C$, permite control sobre cómo se modelan los datos \"extraños\"\n",
    "  - Matemáticamente $C$ le \"da un costo a la función costo\" en el entremamiento. También se puede pdecir que permite un *slack* alrededor del umbral de decisión. (Similar al $\\lambda$ de regularización)\n",
    "  - Si $C$ es suficientemente pequeño, \"se reduce el costo de la función costo\", se permiten *algunas* clasificaciones erróneas (las que podrían corresponder a información extraña o mal clasificada)\n",
    "  - Si $C$ está bien definido, el modelo puede llegar a ser más robusto.\n",
    "\n",
    "  <p align=\"center\">  \n",
    "    <img src=\"imgs/svm4.png\">\n",
    "  </p>\n",
    "\n",
    "- Para cuadrar hiperparámetros ($\\gamma$, C, Kernel) usar cross-validation y cambios exponenciales (probar con $\\gamma=10^{-1},10^0,10^1...$).\n",
    "- Normalizar las características de entrada\n",
    "- Matemáticamente, las SVM son un problema de optimización cuadrático. (Ver documentos)\n",
    "- Multi-clase se hace one vs. all o one vs. one\n",
    "### Documentos\n",
    "- Ver [*Support Vector Machines*](http://cs229.stanford.edu/notes/cs229-notes3.pdf) para las matemáticas de SVM lineal y Kernels.\n",
    "- Ver [*A Practical Guide to Support Vector Classification*](https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf) para trucos prácticos de implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÁRBOLES (DECISION TREES)\n",
    "\n",
    "## DECISION TREES\n",
    "- Ejemplo: Akinator.\n",
    "- Rápidos en entrenamiento y predicción\n",
    "- Intuitivo e interpretable\n",
    "- Tienden a *overfit* (alta varianza)\n",
    "- Categórico y multiclase (nativamente)\n",
    "    - Clasifica hacia diferentes clases\n",
    "\n",
    "<p align=\"center\">  \n",
    "    <img width=50% src=\"imgs/dt1.png\">\n",
    "</p>\n",
    "\n",
    "- Entrenamiento: \n",
    "    - *Gini impurity* ($I_G$): \n",
    "        - Medida de error (más o menos equivalente a la entropía del sistema)\n",
    "        - Definido por: \n",
    "        $$\n",
    "            I_G=\\sum_i^C p_i\\cdot(\\sum_{j\\neq i} p_j)\\\\\n",
    "            =\\sum_i^C \\frac{N_i}{N}\\cdot (1-\\frac{N_i}{N})\n",
    "        $$\n",
    "        - Donde:\n",
    "            - $C$ es el número de clases dentro del espacio (nodo) evaluado.\n",
    "            - $p_x$ es la probabilidad de obtener una muestra de la clase $x$ entre todas las muestras en el nodo evaluado.\n",
    "            - $p_x=\\frac{N_x}{N}$, siendo $N_x$ el número de elementos de clase $x$ y $N$ el número total de elementos.\n",
    "    - $\\Delta I_G$ indica qué tanto mejora el índice de mi nodo si lo divido.\n",
    "        - Favorece divisiones en donde hay nodos puros (Solo hay muestras de una clase dentro del espacio del nodo)\n",
    "        - Si nodo A se divide en B,C. Entonces: $$\\Delta I_G=I_G(A)-\\frac{N(B)}{N(A)}I_G(B)-\\frac{N(C)}{N(A)}I_G(C)$$\n",
    "        - Donde $\\frac{N(X)}{N(Y)}$ indica qué porcentaje de las muestras del nodo Y quedaron en el nodo X tras la división.\n",
    "    - Proceso (es greedy):\n",
    "        - Por cada característica $x^{(i)}$:\n",
    "            - Hallar la ganancia $\\Delta I_G$ tras dividir el árbol en $x^{(i)}$ con cierto umbral óptimo $\\theta$\n",
    "        - Dividir el árbol en la característica que posee mejor ganancia.\n",
    "        - Evaluar condición de parada.\n",
    "    - Condiciones de parada:\n",
    "\n",
    "        - Mínima cantidad de muestras de entrenamiento por nodo.\n",
    "        - Pureza suficiente del nodo.\n",
    "        - Máxima altura del árbol (útil para velocidad).\n",
    "\n",
    "- OOB Error como indicador rápido del error\n",
    "    - Para cuadrar hiperparámetros rapidamente\n",
    "    - Validar qué tan importante es un feature en el modelo\n",
    "        - Durante testing, cambiar un feature a valores aleatorios y ver qué tanto cambia la precisión del modelo\n",
    "        - Si baja mucho al volver un feature inutil, entonces esa característica es muy importante para el modelo\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MÉTODOS DE CONJUNTO\n",
    "- \"Wisdom of crowds\"\n",
    "- Se unen varias unidades predictoras rápidas (varios árboles de decisión, por ejemplo) para obtener un resultado más robusto a través de una decisión conjunta.\n",
    "## RANDOM FORESTS\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"imgs/rf1.png\">\n",
    "</p>\n",
    "\n",
    "- Proceso:\n",
    "    - Se entrenan múltiples árboles \n",
    "    - Cada árbol a entrenar usa un set de entrenamiento diferente (proveniente del original)\n",
    "        - Se usa *Bootstrap sampling* (muestreo aleatorio con reemplazo) para entrenar los diferentes árboles (*Bagging*)\n",
    "    - Para cada árbol se escoge un subconjunto de características sobre el cual se entrena (generalmente se escogen $\\sqrt{n}$ de un total de $n$ características).\n",
    "    - Se promedian los resultados de los diferentes árboles \n",
    "- Método fácilmente paralelizable (mejora velocidad)\n",
    "- Método de **_bagging_** es generalzable a otros modelos no lineales\n",
    "    - Útil para limitar la varianza de modelos que tienden a hacer *overfit*\n",
    "- Los árboles se entrenan sin condición de parada. \n",
    "- El número de árboles es un parámetro del modelo.\n",
    "\n",
    "## BOOSTING\n",
    "- Aprendizaje secuencial: se ajustan las unidades de aprendizaje según su desempeño individual en el modelo.\n",
    "- En la fase de entrenamiento, se asignan pesos a las unidades del modelo (cada árbol) o a sus características, buscando que las más significativas para la predicción tengan más importancia.\n",
    "- Para árboles, usualmente se utiliza una sola división (*stumps*).\n",
    "- Se toma una decisión conjunta según la importancia de cada unidad dentro del modelo (promedio, mayoría)\n",
    "- Implementaciones:\n",
    "    - AdaBoost (Adaptive Boost)\n",
    "    - Gradient Boost\n",
    "    - XGBoost (Extreme Gradient Boost) \n",
    "- Funcionan bien en la práctica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SISTEMAS DE RECOMENDACIÓN\n",
    "- Collaborative Filtering\n",
    "    - Recomienda contenido de otros usuarios que consumen y gustan de contenido similar.\n",
    "    - Puede recomendar tanto usuarios similares (amigos), como elementos similares.\n",
    "    - Utiliza matriz de puntajes (usuarios vs. puntajes de elementos)\n",
    "- Content-based Filtering\n",
    "    - Recomienda contenido similar al consumido por el usuario\n",
    "        - Si alguien solo ve películas de ciencia ficción, recomienda otras películas de ciencia ficción similares.\n",
    "- Se puede tratar como un problema de información faltante\n",
    "    - ¿Qué puntaje le daría este usuario a esta película? \n",
    "        - Regresión\n",
    "    - Entrenar un modelo de predicción para cada elemento?\n",
    "        - Entrenamiento rápido: kNN.\n",
    "            - Intuitivo: ¿vecinos? usuarios que tienen puntajes *similares* a mí.\n",
    "- Semejanza\n",
    "    - ¿Qué usuarios son similares a mí?\n",
    "    - ¿Qué elementos son similares a los que me gustan?\n",
    "    - Medidas de semejanza:\n",
    "        - Tener al menos *k* elementos en común\n",
    "        - Similitud Pearson\n",
    "        - Similitud Coseno\n",
    "- SVD (Singular Value Decomposition)\n",
    "    - Similar a PCA\n",
    "    - Permite inferir acerca de diferentes \"temas\" de películas\n",
    "        - Semejanza\n",
    "    - Se descompone la matriz de puntajes con valores faltantes, luego se reconstruye a partir de los componentes principales.\n",
    "\n",
    "## Recomendaciones basadas en contenido (content-based)\n",
    "- Asumiento que cada elemento del contenido tiene ciertas características (por ejemplo en películas: romance, acción, miedo), es posible formular un problema de regresión lineal para predecir qué películas le gustarían a cada usuario.\n",
    "    - En donde:\n",
    "        - $\\theta^{(j)}$ indica las preferencias del usuario $j$ frente a las diferentes características\n",
    "        - $x^{(i)}$ representa el vector de características del contenido con índice $i$\n",
    "    - El puntaje que un usuario le daría a una película podría representarse como $(\\theta^{(j)})^Tx^{(i)}$\n",
    "    - $\\theta^{(j)}$ se puede aprender si se hace regresión sobre las películas que ya ha visto el usuario $j$\n",
    "##  Recomendaciones basadas en contenido (user-based)\n",
    "- Sistema de recomendación basado en usuarios\n",
    "    - De cada usuario se sabe qué tipo de contenido le gusta\n",
    "    - Entonces, agrupando los puntajes conocidos de cada usuario, es posible conocer qué tipo de contenido es cada elemento (película, por ejemplo)\n",
    "    - Ej. Si sabemos que a David y Carolina les gustan las películas románticas, y le han dado altos puntajes a una película, esta película *probablemente* sea romántica.\n",
    "- Formalizando:\n",
    "- Siendo:\n",
    "    - $\\theta^{(j)}$ es el gusto de los usuarios frente a diferentes tipos de contenido y es conocido (qué tanto le gustan las películas de acción, romance, terror...)\n",
    "    - $x^{(i)}$ es el vector de características del elemento $i$ y se quiere conocer (qué tanto de acción, romance, terror, ..., es la película $i$)\n",
    "    - Regresión sobre los puntajes ya adquiridos para la película $i$\n",
    "\n",
    "## Collaborative filtering\n",
    "- Utilizar recomendaciones ranto user-based como content-based para tener mejores resultados\n",
    "- Resolver un único problema de optimización, minimizando una única función costo que representa la unión de las utilizadas para resolver los problemas de regresión para usuarios y para contenido \n",
    "- Algoritmo: (tomado de Coursera)\n",
    "<p align=\"center\">\n",
    "    <img width=50% src=\"imgs/filtering1.png\">\n",
    "</p>\n",
    "\n",
    "- Donde:\n",
    "    - $n_u$ es el número de usuarios\n",
    "    - $n_m$ es el número de elementos del contenido\n",
    "    - $r(i,j)$ indica si el usuario $j$ ya le dio un puntaje al elemento $i$\n",
    "    - $y(i,j)$ es el puntaje que le dio el usuario $j$ al elemento $i$\n",
    "    - $x^{(i)}$ es el vector de características del elemento $i$\n",
    "        - Indica a qué categorías pertenece el elemento\n",
    "    - $\\theta^{(j)}$ indica qué tanto gusta el usuario $j$ de las diferentes categorías de contenido\n",
    "    - J() es la función costo a minimizar (mínimos cuadrados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTAS\n",
    "\n",
    "### Características\n",
    "- Lo más importante para problemas de clasificación es la selección de **buenas** y suficientes características.\n",
    "- Opciones para optimizar esto:\n",
    "    - Cross-validation\n",
    "    - Regularization\n",
    "    - Feature engineering\n",
    "- Entre más características hayan en un modelo, más aumenta la *varianza* (overfitting). Si un modelo no tiene características suficientes (y, por lo tanto, no realiza una buena predicción), tiene un alto *bias*. Es necesario encontrar un balance.\n",
    "<p align=\"center\">\n",
    "    <img src=\"imgs/caracteristicas1.png\">\n",
    "</p>\n",
    "- En clasificación de imágenes, en vez de utilizar los pixeles como características, es recomendable extraer mejores características de las imágenes (SIFT, *Scale Invariant Feature Transform*)\n",
    "- Graficar resultados de cross-validation para obtener mejor visualización de los hiper-parámetros.\n",
    "- Tener cuidado con la normalización. \n",
    "    - Generalmente se normaliza a la media\n",
    "    - Si la información ya está normalizada, no siempre es necesario normalizar al rangoo std.\n",
    "        - MNIST: normalizar al std baja el performance \n",
    "\n",
    "### Muestreo\n",
    "- Verificar que el balance de clases sea similar para los conjuntos de entrenamiento y pruebas. También para los diferentes conjuntos dentro de cross-validation.\n",
    "- Si hay mucho imbalance de clases, y está afectando mis medidas importantes de clasificación\n",
    "    - Submuestreo\n",
    "    - Sobremuestreo\n",
    "    - Darle pesos diferentes a las clases dentro del modelo\n",
    "- Falta de información:\n",
    "    - Borrar muestras para los que no haya información de alguna característica\n",
    "    - Usar una medida promedio de la característica para rellenar los puntos faltantes\n",
    "    - Usar regresión para \"predecir\" los valores faltantes de una característica\n",
    "    \n",
    "### PCA\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"imgs/pca1.png\">\n",
    "</p>\n",
    "\n",
    "- Para analizar caracerísticas, investigar acerca de PCA (análisis de componentes principales):\n",
    "    - Utilizado para reducir la dimensionalidad de los datos.\n",
    "    - \"Proyecta\" información de alta dimensionalidad en componentes representativos de esta.\n",
    "    - Todos los componentes principales son ortogonales entre sí (independientes).\n",
    "    - Cada componente principal subsecuente contiene menos información significativa que el anterior (representa menos varianza).\n",
    "    - Para entrenar un modelo, es posible escoger los $n$ componentes principales que representan la mayoría (95% - 99%) de la varianza en los datos.\n",
    "\n",
    "- Ejemplos:\n",
    "    - Puntos en un espacio 3D, en los que la mayoría se encuentran dentro de un mismo plano, se pueden representar en dos dimensiones.\n",
    "    - (wiki) Un conjunto de datos puede describir la altura y el peso de 100 niños entre 2 y 15 años. Ambas variables están, obviamente, correlacionadas (los niños de más edad son más altos y pesan más).\n",
    "        - El análisis de componentes principales describe los datos en términos de dos nuevas variables. \n",
    "        - El primer componente se puede interpretar como \"tamaño\" o \"edad\" y recoge la mayor parte de la varianza de los datos originales. \n",
    "        - El segundo componente describe variabilidad en los datos que no está correlacionada en absoluto con el primer componente principal \"tamaño\", y (probablemente) sea difícil de interpretar. \n",
    "        - Si el objetivo es reducir la dimensionalidad de los datos, se puede descartar este segundo componente principal. \n",
    "        - Lo mismo aplica si el conjunto de datos contiene un número mayor de variables que se pueden interpretar como medidas aproximadas de \"tamaño\". Por ejemplo, longitud del fémur, longitud de los brazos, peso, altura, etc. Un conjunto de datos de este tipo podría describirse generalmente con un único componente principal que se podría interpretar como \"tamaño\" o \"edad\".\n",
    "- (LDA/SVD)\n",
    "- Denro de un modelo, hacer entrenar PCA únicamente con los datos de entrenamiento, luego mapear los datos de prueba con el modelo PCA ajustado a partir de los datos de entrenamiento.\n",
    "    - Aplica para cross-validation: únicamente hacer el PCA con los datos de entrenamiento de cada iteración, y mapear el set de validación a este PCA ya ajustado.\n",
    "\n",
    "### Medidas (clasificación)\n",
    "- Curvas ROC (Tasa de verdadero positivo vs falso positivo)\n",
    "- Probabilidad de que:\n",
    "    - Dado un ejemplo positivo, ¿yo haga una predicción correcta?\n",
    "    - Dada una predicción positiva, ¿realmente sea un ejemplo positivo?\n",
    "- Matriz de confusión (multiclase)\n",
    "\n",
    "### Clasificación vs. Regresión\n",
    "- La regresión entiende intermedios entre clases\n",
    "- La regresión preserva las distancias entre clases\n",
    "    - Por ejemplo para un problema de sentiment analysis:\n",
    "        - Para clasificación: si lo correcto es 2 estrellas, predecir 1 estrella es el mismo error que predecir 5 estrellas\n",
    "        - Para regresión: si lo correcto es 2 estrellas, predecir 5 estrellas es peor (más error) que predecir 1 estrella \n",
    "\n",
    "### Cómo escoger modelos\n",
    "- Excelente pregunta.,.,.,,.,.,.,.,,,\n",
    "- Según relación entre número de ejemplos y número de características\n",
    "    - (Tomado de CS109:)\n",
    "    \n",
    "<p align=\"center\">\n",
    "    <img width=50% src=\"imgs/cual1.png\">\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}